<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fast On-device LLM Inference with NPUs - 论文阅读报告</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #2c3e50;
            background: linear-gradient(135deg, #e3f2fd 0%, #f8f9fa 100%);
            min-height: 100vh;
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 3rem;
            padding: 2rem;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(10px);
            animation: slideInFromTop 1s ease-out;
            border: 1px solid rgba(100, 181, 246, 0.2);
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            background: linear-gradient(45deg, #1976d2, #42a5f5);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .author-info {
            background: linear-gradient(135deg, #42a5f5, #64b5f6);
            color: white;
            padding: 1rem 2rem;
            border-radius: 15px;
            margin: 1rem 0;
            box-shadow: 0 4px 15px rgba(66, 165, 245, 0.3);
        }

        .paper-title {
            font-size: 1.3rem;
            color: #546e7a;
            font-style: italic;
            margin-top: 1rem;
        }

        .section {
            margin-bottom: 3rem;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 2rem;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.08);
            backdrop-filter: blur(10px);
            transform: translateY(50px);
            opacity: 0;
            transition: all 0.6s ease;
            border: 1px solid rgba(100, 181, 246, 0.1);
        }

        .section.visible {
            transform: translateY(0);
            opacity: 1;
        }

        .section h2 {
            font-size: 2rem;
            margin-bottom: 1.5rem;
            color: #1565c0;
            border-left: 5px solid #42a5f5;
            padding-left: 1rem;
            position: relative;
        }

        .section h2::after {
            content: '';
            position: absolute;
            bottom: -10px;
            left: 0;
            width: 50px;
            height: 3px;
            background: linear-gradient(45deg, #42a5f5, #64b5f6);
            border-radius: 2px;
        }

        .section h3 {
            color: #1976d2;
            margin: 1.5rem 0 1rem 0;
            font-size: 1.4rem;
        }

        .content-with-image {
            display: flex;
            gap: 2rem;
            align-items: flex-start;
            margin: 2rem 0;
            flex-wrap: wrap;
        }

        .content-text {
            flex: 1;
            min-width: 300px;
        }

        .content-image {
            flex: 0 0 350px;
            min-width: 300px;
        }

        /* 专门为图4添加的居中样式 */
        .content-text.centered {
            text-align: center;
        }

        .highlight-box {
            background: linear-gradient(135deg, rgba(66, 165, 245, 0.1), rgba(100, 181, 246, 0.1));
            border-left: 4px solid #42a5f5;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 10px;
            position: relative;
            overflow: hidden;
        }

        .highlight-box::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
            transition: left 0.5s;
        }

        .highlight-box:hover::before {
            left: 100%;
        }

        .tech-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }

        .tech-card {
            background: linear-gradient(135deg, #81c784 0%, #66bb6a 100%);
            color: white;
            padding: 1.5rem;
            border-radius: 15px;
            box-shadow: 0 6px 20px rgba(102, 187, 106, 0.3);
            transform: translateY(10px);
            transition: all 0.3s ease;
        }

        .tech-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 12px 30px rgba(102, 187, 106, 0.4);
        }

        .tech-card h3 {
            color: white;
            margin-bottom: 1rem;
        }

        /* 新增：技术创新单元样式 */
        .tech-innovation-unit {
            margin: 3rem 0;
            background: rgba(255, 255, 255, 0.9);
            border-radius: 15px;
            padding: 2rem;
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.05);
            border: 1px solid rgba(100, 181, 246, 0.15);
        }

        .tech-innovation-header {
            background: linear-gradient(135deg, #81c784 0%, #66bb6a 100%);
            color: white;
            padding: 1.5rem;
            border-radius: 12px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 15px rgba(102, 187, 106, 0.3);
        }

        .tech-innovation-header h3 {
            color: white;
            margin-bottom: 1rem;
            font-size: 1.5rem;
        }

        .tech-content-layout {
            display: flex;
            gap: 2rem;
            align-items: flex-start;
            flex-wrap: wrap;
        }

        .tech-description {
            flex: 1;
            min-width: 350px;
        }

        .tech-image {
            flex: 0 0 400px;
            min-width: 350px;
            text-align: center;
        }

        .performance-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }

        .stat-card {
            background: linear-gradient(135deg, #7986cb, #9575cd);
            color: white;
            padding: 1.5rem;
            border-radius: 15px;
            text-align: center;
            animation: countUp 2s ease-out;
            box-shadow: 0 6px 20px rgba(121, 134, 203, 0.3);
            word-wrap: break-word;
            overflow-wrap: break-word;
        }

        .stat-number {
            font-size: 1.8rem; /* 减小字号解决溢出问题 */
            font-weight: bold;
            display: block;
            margin-bottom: 0.5rem;
            word-break: break-all;
        }

        .stat-label {
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .report-image {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            margin-bottom: 0.5rem;
            transition: transform 0.3s ease;
        }
        
        .report-image#fig4 { /* 专门为图4设置缩小尺寸 */
            max-width: 80%;
            display: inline-block; /* 确保居中生效 */
        }

        .report-image:hover {
            transform: scale(1.02);
        }

        .image-caption {
            text-align: center;
            margin-top: 8px;
            color: #546e7a;
            font-style: italic;
            font-size: 0.95rem;
        }

        .image-placeholder {
            background: linear-gradient(135deg, rgba(66, 165, 245, 0.1), rgba(100, 181, 246, 0.1));
            border: 2px dashed #42a5f5;
            padding: 2rem;
            margin: 1rem 0;
            text-align: center;
            border-radius: 10px;
            color: #1976d2;
            font-style: italic;
            transition: all 0.3s ease;
        }

        .image-placeholder:hover {
            background: linear-gradient(135deg, rgba(66, 165, 245, 0.15), rgba(100, 181, 246, 0.15));
            transform: scale(1.02);
        }

        .advantages-list {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1rem;
            margin: 1.5rem 0;
        }

        .advantage-item {
            background: linear-gradient(135deg, #e1f5fe 0%, #f3e5f5 100%);
            padding: 1.5rem;
            border-radius: 12px;
            border-left: 4px solid #29b6f6;
            transition: all 0.3s ease;
            box-shadow: 0 2px 10px rgba(41, 182, 246, 0.1);
        }

        .advantage-item:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 20px rgba(41, 182, 246, 0.2);
        }

        .improvement-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }

        .improvement-card {
            background: linear-gradient(135deg, #fff3e0 0%, #f3e5f5 100%);
            padding: 1.5rem;
            border-radius: 15px;
            border-left: 4px solid #ff9800;
            box-shadow: 0 4px 15px rgba(255, 152, 0, 0.1);
            transition: all 0.3s ease;
        }

        .improvement-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(255, 152, 0, 0.2);
        }

        .improvement-card h3 {
            color: #f57c00;
            margin-bottom: 1rem;
        }

        .floating-particle {
            position: fixed;
            pointer-events: none;
            opacity: 0.05;
            z-index: -1;
            animation: float 6s ease-in-out infinite;
        }

        @keyframes slideInFromTop {
            from {
                transform: translateY(-100px);
                opacity: 0;
            }
            to {
                transform: translateY(0);
                opacity: 1;
            }
        }

        @keyframes countUp {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes float {
            0%, 100% { transform: translateY(0px) rotate(0deg); }
            50% { transform: translateY(-20px) rotate(180deg); }
        }

        .scroll-indicator {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 4px;
            background: linear-gradient(45deg, #42a5f5, #64b5f6);
            transform-origin: left;
            transform: scaleX(0);
            transition: transform 0.3s ease;
            z-index: 1000;
        }

        .conclusion-box {
            background: linear-gradient(135deg, #e8f5e8 0%, #f1f8e9 100%);
            border: 2px solid #4caf50;
            border-radius: 15px;
            padding: 2rem;
            margin: 2rem 0;
            position: relative;
            overflow: hidden;
        }

        .conclusion-box::before {
            content: '🎯';
            position: absolute;
            top: 1rem;
            right: 1rem;
            font-size: 2rem;
            opacity: 0.3;
        }

        /* 新增样式：整页宽度图片 */
        .full-width-image {
            margin: 2rem -2rem;
            text-align: center;
        }

        .full-width-image .report-image {
            max-width: 95%;
        }

        /* 新增样式：并排图片容器 - 修改为上下排列 */
        .side-by-side-images {
            display: flex;
            flex-direction: column; /* 改为垂直排列 */
            gap: 1rem;
            margin: 2rem -2rem;
            align-items: center;
        }

        .side-by-side-images .report-image {
            max-width: 100%; /* 确保图片占满整行 */
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2rem;
            }
            
            .section {
                padding: 1.5rem;
                margin-bottom: 2rem;
            }
            
            .tech-grid,
            .performance-stats,
            .advantages-list,
            .improvement-grid {
                grid-template-columns: 1fr;
            }

            .content-with-image,
            .tech-content-layout {
                flex-direction: column;
            }

            .content-image,
            .tech-image {
                flex: none;
            }

            .tech-description {
                min-width: auto;
            }

            .stat-number {
                font-size: 1.8rem;
            }

            .full-width-image,
            .side-by-side-images {
                margin: 2rem -1.5rem;
            }

            .tech-innovation-unit {
                padding: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="scroll-indicator"></div>
    
    <!-- 浮动粒子效果 -->
    <div class="floating-particle" style="top: 10%; left: 10%; width: 20px; height: 20px; background: #42a5f5; border-radius: 50%;"></div>
    <div class="floating-particle" style="top: 20%; right: 10%; width: 15px; height: 15px; background: #66bb6a; border-radius: 50%;"></div>
    <div class="floating-particle" style="bottom: 30%; left: 20%; width: 25px; height: 25px; background: #9575cd; border-radius: 50%;"></div>

    <div class="container">
        <header class="header">
            <h1>Fast On-device LLM Inference with NPUs</h1>
            <div class="author-info">
                <strong>北大软微论文阅读任务</strong><br>
                北京工业大学 张禹喆 | 专业第一 | 四篇CCF论文
            </div>
            <div class="paper-title">
                论文阅读报告：移动端NPU加速大语言模型推理系统研究
            </div>
        </header>

        <section class="section">
            <h2>一、该论文解决了什么问题？有何意义？你对该问题有何评价？</h2>
            
            <div class="content-with-image">
                <div class="content-text">
                    <div class="highlight-box">
                        <h3>🎯 核心问题识别</h3>
                        <p>该论文瞄准了当前移动端大语言模型推理中的一个关键瓶颈问题：<strong>预填充（prefill）阶段的高延迟</strong>。随着隐私保护意识的增强和移动端模型能力的提升，越来越多的应用场景需要在设备本地运行大语言模型，如Apple Intelligence和Android AI Core等。</p>
                        <p>作者通过深入分析发现，在典型的移动应用中，预填充阶段占据了总推理时间的88.3%-98.8%（CPU）和54.2%-91.7%（GPU）。以UI自动化任务为例，处理一个5步骤的UI任务需要超过40秒，这在实际应用中是不可接受的。</p>
                    </div>
                </div>
                <div class="content-image">
                    <img src="fig/图1.png" alt="移动端LLM推理系统面临的核心挑战分析" class="report-image">
                    <p class="image-caption">📊 图1：移动端LLM推理系统面临的核心挑战分析</p>
                </div>
            </div>

            <div class="performance-stats">
                <div class="stat-card">
                    <span class="stat-number">88.3%-98.8%</span>
                    <span class="stat-label">CPU预填充阶段占比</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">54.2%-91.7%</span>
                    <span class="stat-label">GPU预填充阶段占比</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">40+秒</span>
                    <span class="stat-label">5步骤UI任务处理时间</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">73 TOPS</span>
                    <span class="stat-label">移动端NPU计算能力</span>
                </div>
            </div>

            <h3>🔬 研究意义与价值评估</h3>
            <div class="advantages-list">
                <div class="advantage-item">
                    <strong>技术突破</strong><br>
                    首次系统性地探索了移动端NPU在LLM推理中的应用潜力，NPU具有高达73 TOPS的整数运算能力，但在LLM推理领域一直未得到充分利用。
                </div>
                <div class="advantage-item">
                    <strong>应用价值</strong><br>
                    直接服务于当前蓬勃发展的"端侧AI生态"，随着苹果、谷歌等巨头大力推进端侧AI能力，移动端LLM的性能优化已成为产业发展的关键制约因素。
                </div>
                <div class="advantage-item">
                    <strong>产业影响</strong><br>
                    为移动设备承载更复杂AI任务奠定技术基础，不仅能够显著提升用户体验，还能为移动设备承载更复杂AI任务提供支撑。
                </div>
                <div class="advantage-item">
                    <strong>发展前瞻</strong><br>
                    在云端LLM推理技术日趋成熟的背景下，端侧推理正成为下一个技术竞争的焦点，具有重要的学术价值和工程实用价值。
                </div>
            </div>
        </section>

        <section class="section">
            <h2>二、论文所提方法或技术的创新点有哪些？你对其有何评价？</h2>

            <div class="content-with-image">
                <div class="content-text">
                    <div class="highlight-box">
                        <h3>🏗️ 架构设计的系统性创新</h3>
                        <p>本文最大的创新在于提出了一套完整的移动端NPU-LLM协同推理架构。这不是简单的硬件移植，而是针对移动端NPU特性和LLM计算模式的深度重构。作者从三个层次进行了系统性重设计：<strong>提示级别（prompt level）、张量级别（tensor level）和块级别（block level）</strong>。</p>
                        <p>这种多层次的重构策略体现了作者对问题本质的深刻理解。与简单的算子级优化不同，这种系统级重构能够在保证功能正确性的前提下，最大化地发挥NPU的计算优势。</p>
                    </div>
                </div>
                <div class="content-image">
                    <img src="fig/fig6.png" alt="llm.npu系统的完整工作流程" class="report-image">
                    <p class="image-caption">🔄 图2：llm.npu系统的完整工作流程，包括准备阶段和执行阶段的详细步骤</p>
                </div>
            </div>

            <h3>🔧 关键技术创新的深度剖析</h3>

            <!-- 技术创新点1: Chunk-sharing Graphs -->
            <div class="tech-innovation-unit">
                <div class="tech-innovation-header">
                    <h3>🧩 Chunk-sharing Graphs</h3>
                    <p><strong>核心创新：</strong>将LLM算子分为静态算子和动态算子两类，通过预构建固定长度的子图避免重复的图构建开销。</p>
                </div>
                <div class="tech-content-layout">
                    <div class="tech-description">
                        <p>传统的NPU推理需要为每个不同长度的输入重新构建和优化计算图，这个过程往往需要数十秒。作者巧妙地将LLM的计算图分解为可重用的固定长度子图，通过预构建和缓存这些子图，显著减少了运行时的图构建开销。</p>
                        <p><strong>技术成果：</strong>在Qwen1.5-1.8B模型中，144个子图中有120个可以共享，内存消耗降低了75%。这种设计不仅提升了性能，还大幅减少了内存占用。</p>
                        <p><strong>创新意义：</strong>这是首次在移动端NPU上实现大规模计算图重用的系统，为后续相关研究奠定了重要基础。</p>
                    </div>
                    <div class="tech-image">
                        <img src="fig/fig7.png" alt="Chunk-sharing Graph技术的核心设计思想对比" class="report-image">
                        <p class="image-caption">📊 图3：Chunk-sharing Graph技术的核心设计思想对比</p>
                    </div>
                </div>
            </div>

            <!-- 技术创新点2: Shadow Outlier Execution -->
            <div class="tech-innovation-unit">
                <div class="tech-innovation-header">
                    <h3>👤 Shadow Outlier Execution</h3>
                    <p><strong>核心创新：</strong>解决了激活异常值导致的量化精度损失问题，同时避免了传统分组量化方法在NPU上的效率损失。</p>
                </div>
                <div class="tech-content-layout">
                    <div class="tech-description">
                        <p>将MatMul操作分解为两部分：在NPU上处理正常范围内的激活，在CPU上处理异常值。这种设计既保证了计算精度，又避免了NPU效率的损失，实现了数学等式分解思想与硬件特性的完美结合。</p>
                        <p><strong>技术优势：</strong>通过动态识别和分离异常值，确保了NPU能够专注于处理规律性较强的数据，而CPU则负责处理复杂的异常情况。这种协同计算模式充分发挥了异构计算的优势。</p>
                        <p><strong>实现细节：</strong>系统能够在推理过程中动态检测激活异常值，并将相应的计算任务无缝转移到CPU，整个过程对用户透明。</p>
                    </div>
                    <div class="tech-image">
                        <img src="fig/图4.png" alt="阴影异常值执行的工作流程" class="report-image">
                        <p class="image-caption">🔧 图4：阴影异常值执行的工作流程，展示了如何在NPU和CPU之间协同处理激活异常值</p>
                    </div>
                </div>
            </div>

            <!-- 技术创新点3: Out-of-order Subgraph Execution -->
            <div class="tech-innovation-unit">
                <div class="tech-innovation-header">
                    <h3>⚡ Out-of-order Subgraph Execution</h3>
                    <p><strong>核心创新：</strong>基于NPU负载优先的调度策略，传统的按序执行会产生大量的执行气泡。</p>
                </div>
                <div class="tech-content-layout">
                    <div class="tech-description">
                        <p>作者提出了基于NPU负载优先的调度策略，通过乱序执行来最大化NPU的利用率。系统能够智能分析子图之间的依赖关系，在保证计算正确性的前提下重新排序执行顺序。</p>
                        <p><strong>性能提升：</strong>从传统37%的气泡率降低到0.7%，显著提升了系统的整体执行效率。这种改进直接转化为用户体验的显著提升。</p>
                        <p><strong>算法优势：</strong>采用贪心调度算法，在保证实时性的同时获得了近似最优的调度效果。与复杂的全局优化算法相比，该方法在移动端具有更好的实用性。</p>
                    </div>
                    <div class="tech-image">
                        <img src="fig/subgraph.png" alt="乱序子图执行调度策略" class="report-image">
                        <p class="image-caption">🔄 图5：乱序子图执行调度策略，展示了如何通过智能调度减少执行气泡</p>
                    </div>
                </div>
            </div>

            <div class="conclusion-box">
                <h3>💡 创新点综合评价</h3>
                <p>这些技术创新的价值不仅在于单点突破，更在于系统性的协同设计。作者没有停留在算法层面的优化，而是从系统架构的角度重新思考了移动端LLM推理的技术路线。特别值得说明的是，作者在保证功能正确性的前提下，巧妙地平衡了性能、精度和资源消耗的多重约束。阴影异常值执行技术就是这种平衡艺术的典型体现——<strong>既不牺牲精度，也不放弃NPU的计算优势</strong>。</p>
            </div>
        </section>

        <section class="section">
            <h2>三、对该论文阐述的问题或方法有何改进或进一步建议？</h2>

            <div class="highlight-box">
                <h3>🔧 系统架构层面的改进空间</h3>
                <p>虽然llm.npu在移动端NPU利用方面取得了突破性进展，但仍有一些值得深入探索的改进方向。当前的块长度选择策略相对静态，作者通过离线profiling确定了256的块长度，这种静态配置可能无法适应不同模型和不同输入模式的最优需求。</p>
            </div>

            <!-- 图5 - 整页宽度展示 -->
            <div class="full-width-image">
                <img src="fig/图5.png" alt="自适应块长度选择机制的系统设计" class="report-image">
                <p class="image-caption">🏗️ 图6：自适应块长度选择机制的系统设计</p>
            </div>

            <div class="improvement-grid">
                <div class="improvement-card">
                    <h3>📊 自适应块长度选择机制</h3>
                    <p>引入轻量级的在线profiling系统，根据当前模型的计算特征、输入长度分布和硬件负载情况动态调整块长度。这种动态调整可能需要额外的计算开销，但考虑到不同场景下性能差异的显著性，这种投入是值得的。</p>
                </div>
                <div class="improvement-card">
                    <h3>🎯 动态异常值检测优化</h3>
                    <p>当前系统使用固定阈值来识别异常值，这种方法虽然简单有效，但可能无法适应不同层和不同输入的激活分布差异。可以考虑引入基于统计学习的动态阈值调整机制，或者使用更复杂的异常值检测算法。</p>
                </div>
                <div class="improvement-card">
                    <h3>🤖 强化学习调度策略</h3>
                    <p>设计基于强化学习的调度策略，通过在线学习来适应不同的工作负载模式。可以设计一个轻量级的actor-critic架构，其中actor负责调度决策，critic负责评估调度质量。</p>
                </div>
                <div class="improvement-card">
                    <h3>🔗 跨平台适应性增强</h3>
                    <p>当前的实现主要针对Qualcomm Hexagon NPU，但不同厂商的NPU在架构和指令集方面存在显著差异。建议开发一套通用的NPU抽象层，类似于ONNX在深度学习框架中的作用。</p>
                </div>
            </div>

            <h3>⚡ 算法优化的深化方向</h3>
            <div class="highlight-box">
                <p>在乱序执行调度算法方面，当前的贪心策略虽然在实践中表现良好，但理论上仍有优化空间。同时，可以进一步探索模型压缩技术与NPU优化的结合。当前工作主要关注推理阶段的优化，但如果能够在模型压缩阶段就考虑NPU的计算特性，可能会获得更好的端到端性能。例如，可以设计NPU-aware的剪枝策略，优先保留对NPU友好的计算模式。</p>
            </div>
        </section>

        <section class="section">
            <h2>四、对论文的实验部分有何评价和进一步建议？</h2>

            <div class="content-with-image">
                <div class="content-text">
                    <div class="highlight-box">
                        <h3>✅ 实验设计的全面性评价</h3>
                        <p>本文的实验设计相当全面，涵盖了性能、精度、能耗和内存消耗等多个维度。作者选择了5个代表性的移动端LLM（从1.8B到7B参数），以及多种真实应用场景的数据集，这种实验设置确保了结果的代表性和可信度。</p>
                        <p>实验的结果非常出色：在1024 token的提示长度下，llm.npu实现了最高43.6倍的速度提升和59.5倍的能耗降低。更重要的是，这是首个在移动设备上实现超过1000 tokens/sec预填充速度的系统。</p>
                    </div>
                </div>
            </div>

            <div class="performance-stats">
                <div class="stat-card">
                    <span class="stat-number">43.6倍</span>
                    <span class="stat-label">最高速度提升</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">59.5倍</span>
                    <span class="stat-label">能耗降低</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">1000+</span>
                    <span class="stat-label">tokens/sec预填充速度</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">&lt;1%</span>
                    <span class="stat-label">精度损失</span>
                </div>
            </div>

            <!-- 图14和图15 - 整页宽度上下排列 -->
            <div class="side-by-side-images">
                <img src="fig/fig14.png" alt="在不同设备和不同提示长度下的性能对比" class="report-image">
                <p class="image-caption">📈 图7：在不同设备和不同提示长度下，llm.npu相比baseline方法的速度优势</p>
                
                <img src="fig/fig15.png" alt="能耗对比结果" class="report-image">
                <p class="image-caption">🔋 图8：llm.npu在能耗方面的显著优势（有益于移动设备电池寿命）</p>
            </div>

            <div class="content-with-image">
                <div class="content-text">
                    <h3>📊 实验方法论的深度分析</h3>
                    <p>作者在实验方法论方面表现出了严谨的学术态度。特别值得注意的是消融实验的设计，清晰地展示了每个技术组件的贡献。从结果可以看出，阴影异常值执行贡献了3.91-8.68倍的性能提升，这证明了该技术的重要性。</p>
                </div>
                <div class="content-image">
                    <img src="fig/图7.png" alt="消融实验结果" class="report-image">
                    <p class="image-caption">🔍 图9：各技术组件的性能贡献消融实验结果</p>
                </div>
            </div>

            <h3>🔍 各技术组件的性能贡献分析</h3>
            <div class="tech-grid">
                <div class="tech-card">
                    <h3>Chunk-sharing</h3>
                    <p>相比朴素NPU移植，性能提升<strong>1.46-5.09倍</strong></p>
                    <p>通过预构建固定长度子图显著减少图构建时间</p>
                </div>
                <div class="tech-card">
                    <h3>Shadow Outlier</h3>
                    <p>相比Chunk-sharing，性能提升<strong>3.91-8.68倍</strong></p>
                    <p>动态处理异常值，实现精度与效率的完美平衡</p>
                </div>
                <div class="tech-card">
                    <h3>Out-of-order</h3>
                    <p>相比Shadow Outlier，性能提升<strong>18-44%</strong></p>
                    <p>智能调度策略显著减少执行气泡</p>
                </div>
            </div>

            <div class="highlight-box">
                <h3>🔍 进一步实验建议</h3>
                <div class="advantages-list">
                    <div class="advantage-item">
                        <strong>① 扩展硬件平台测试</strong><br>
                        当前实验主要在两款小米设备上进行，建议扩展到更多厂商和更多代际的设备上，特别是苹果、华为等主流厂商的设备。不同厂商的NPU架构差异可能会显著影响性能表现。
                    </div>
                    <div class="advantage-item">
                        <strong>② 增加多样化应用场景</strong><br>
                        虽然作者测试了UI自动化、邮件回复等场景，但还可以考虑更多新兴的应用场景，如实时语音助手、增强现实应用等。这些场景对延迟的要求更加严格。
                    </div>
                    <div class="advantage-item">
                        <strong>③ 对比更多先进方法</strong><br>
                        随着该领域的快速发展，建议持续更新对比方法，包括最新的量化技术、推理加速方法等。特别是可以考虑引入一些专门针对移动端优化的最新方法。
                    </div>
                    <div class="advantage-item">
                        <strong>④ 鲁棒性测试</strong><br>
                        建议增加对异常输入、边界条件的测试，评估系统在各种极端情况下的表现。虽然这对于写论文用处不太大，但对于实际部署具有重要意义。
                    </div>
                </div>
            </div>

            <!-- 图8 - 置于"进一步实验建议"部分 -->
            <div class="full-width-image">
                <img src="fig/图8.png" alt="进一步实验建议的系统化框架" class="report-image">
                <p class="image-caption">💡 图10：进一步实验建议的系统化框架</p>
            </div>

            <div class="content-with-image">
                <div class="content-text">
                    <div class="conclusion-box">
                        <h3>🎯 总结评价</h3>
                        <p>通过这些改进，可以进一步验证llm.npu方法的普适性和实用性，为该技术的广泛应用奠定更坚实的基础。同时，这些实验结果也能够为后续研究提供更丰富的insights和指导。总体来说，这项研究在移动端LLM推理优化领域做出了重要贡献，不仅提出了创新的技术方案，还通过详实的实验验证了方案的有效性。随着移动端AI应用的不断发展，这类系统级优化研究将变得越来越重要，而这篇论文的工作无疑为这一领域树立了新的标杆。</p>
                    </div>
                </div>
            </div>
        </section>
    </div>

    <script>
        // 滚动进度指示器
        window.addEventListener('scroll', () => {
            const scrollIndicator = document.querySelector('.scroll-indicator');
            const scrollTop = window.pageYOffset;
            const docHeight = document.body.offsetHeight;
            const winHeight = window.innerHeight;
            const scrollPercent = scrollTop / (docHeight - winHeight);
            scrollIndicator.style.transform = `scaleX(${scrollPercent})`;
        });

        // 滚动动画
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        }, observerOptions);

        document.querySelectorAll('.section').forEach(section => {
            observer.observe(section);
        });

        // 平滑滚动
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });

        // 动态粒子效果
        function createParticle() {
            const particle = document.createElement('div');
            particle.className = 'floating-particle';
            particle.style.cssText = `
                position: fixed;
                width: ${Math.random() * 8 + 3}px;
                height: ${Math.random() * 8 + 3}px;
                background: ${['#42a5f5', '#66bb6a', '#9575cd', '#29b6f6'][Math.floor(Math.random() * 4)]};
                border-radius: 50%;
                top: ${Math.random() * 100}%;
                left: ${Math.random() * 100}%;
                pointer-events: none;
                opacity: 0.05;
                z-index: -1;
                animation: float ${Math.random() * 4 + 4}s ease-in-out infinite;
            `;
            document.body.appendChild(particle);
            
            setTimeout(() => {
                particle.remove();
            }, 8000);
        }

        setInterval(createParticle, 3000);

        // 数字动画效果
        function animateNumbers() {
            const statNumbers = document.querySelectorAll('.stat-number');
            statNumbers.forEach(stat => {
                const text = stat.textContent;
                const number = parseFloat(text.replace(/[^\d.]/g, ''));
                if (!isNaN(number) && number > 0) {
                    stat.innerHTML = '0';
                    let current = 0;
                    const increment = number / 30;
                    const timer = setInterval(() => {
                        current += increment;
                        if (current >= number) {
                            stat.innerHTML = text;
                            clearInterval(timer);
                        } else {
                            const currentText = text.replace(/[\d.]+/, Math.floor(current).toString());
                            stat.innerHTML = currentText;
                        }
                    }, 50);
                }
            });
        }

        // 当统计卡片进入视窗时触发数字动画
        const statsObserver = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    animateNumbers();
                    statsObserver.unobserve(entry.target);
                }
            });
        });

        document.querySelectorAll('.performance-stats').forEach(stats => {
            statsObserver.observe(stats);
        });

        // 图片加载失败处理
        document.querySelectorAll('.report-image').forEach(img => {
            img.onerror = function() {
                this.style.display = 'none';
                const parent = this.parentNode;
                const placeholder = document.createElement('div');
                placeholder.className = 'image-placeholder';
                placeholder.innerHTML = `🔧 图片加载失败: ${this.src}`;
                parent.appendChild(placeholder);
            };
        });
    </script>
</body>
</html>